#### **1. Определение LRU-кэша**  
LRU (Least Recently Used) — это алгоритм кэширования, при котором вытесняются **наименее недавно использованные** элементы при переполнении.  

**Основные операции**:  
- `get(key)` — получить значение по ключу (обновляет порядок использования).  
- `put(key, value)` — добавить или обновить элемент (вытесняет старый при переполнении).  

#### **2. Структуры данных**  
Для эффективной реализации (O(1) на операции) используются:  
1. **Хеш-таблица** (`std::unordered_map`):  
   - Быстрый доступ к элементам по ключу.  
   - Хранит ключи и итераторы на узлы в списке.  
2. **Двусвязный список** (`std::list`):  
   - Упорядочивает элементы по времени использования.  
   - Голова списка — наименее используемый элемент, хвост — наиболее используемый.  

#### **3. Реализация на C++**  
```cpp
#include <unordered_map>
#include <list>

class LRUCache {
private:
    int capacity;
    std::list<std::pair<int, int>> cache;  // Список пар (ключ, значение)
    std::unordered_map<int, std::list<std::pair<int, int>>::iterator> map;  // Ключ → итератор в списке

public:
    LRUCache(int capacity) : capacity(capacity) {}

    int get(int key) {
        if (map.find(key) == map.end()) return -1;  // Ключ не найден
        auto it = map[key];
        int value = it->second;
        cache.erase(it);                          // Удаляем из текущей позиции
        cache.push_back({key, value});            // Добавляем в конец (последний использованный)
        map[key] = --cache.end();                 // Обновляем итератор в хеш-таблице
        return value;
    }

    void put(int key, int value) {
        if (map.find(key) != map.end()) {
            cache.erase(map[key]);  // Удаляем старый элемент
        } else if (cache.size() >= capacity) {
            int lru_key = cache.front().first;
            map.erase(lru_key);     // Удаляем из хеш-таблицы
            cache.pop_front();      // Удаляем из списка (LRU-элемент)
        }
        cache.push_back({key, value});
        map[key] = --cache.end();   // Сохраняем итератор
    }
};
```

#### **4. Пример работы**  
```cpp
int main() {
    LRUCache cache(2);
    cache.put(1, 1);       // Кэш: [(1,1)]
    cache.put(2, 2);       // Кэш: [(1,1), (2,2)]
    std::cout << cache.get(1) << "\n";  // 1 → Кэш: [(2,2), (1,1)]
    cache.put(3, 3);       // Вытесняем (2,2). Кэш: [(1,1), (3,3)]
    std::cout << cache.get(2) << "\n";  // -1 (не найден)
}
```
**Вывод**:  
```
1
-1
```

#### **5. Объяснение операций**  
- **`get(key)`**:  
  1. Проверяем наличие ключа в хеш-таблице.  
  2. Перемещаем элемент в конец списка (обновляем порядок).  
- **`put(key, value)`**:  
  1. Если ключ существует — обновляем значение и порядок.  
  2. Если кэш переполнен — удаляем голову списка (LRU-элемент).  
  3. Добавляем новый элемент в конец списка.  

#### **6. Производительность**  
| Операция | Сложность |
| -------- | --------- |
| `get()`  | O(1)      |
| `put()`  | O(1)      |

**Почему O(1)?**  
- Хеш-таблица дает мгновенный доступ к итератору.  
- Вставка/удаление в начало/конец списка — O(1).  

#### **7. Оптимизации и расширения**  
1. **Шаблоны**:  
   ```cpp
   template <typename K, typename V>
   class LRUCache { ... };
   ```  
2. **Потокобезопасность**: Добавьте мьютексы для многопоточности.  
3. **Кастомные аллокаторы**: Для оптимизации памяти.  

**Идеальный ответ:**
_LRU-кэш реализуется комбинацией **хеш-таблицы** (быстрый доступ) и **двусвязного списка** (учёт порядка использования)._
_- **`get(key)`** перемещает элемент в конец списка._
_- **`put(key, value)`** вытесняет LRU-элемент при переполнении._
_- **Сложность операций**: O(1)._
_**Пример использования**:_
```cpp
LRUCache cache(2);
cache.put("A", 100);  
cache.put("B", 200);  
std::cout << cache.get("A");  // 100 → "A" становится последним использованным.
```